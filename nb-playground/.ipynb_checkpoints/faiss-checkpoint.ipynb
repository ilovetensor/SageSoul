{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdabb455-1fe5-4c60-b6d5-da28c05aa516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import gensim\n",
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db15a2-e83d-480b-a9f9-16f02bd7c40f",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "752d58ba-a90a-4be3-92b5-679641d4cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_from_url(url):\n",
    "    \"\"\"Loads the texts and apply some preprocessing over html\n",
    "    to extract the paragraphs from the page\n",
    "    \"\"\"\n",
    "    # load html\n",
    "    page = urlopen(url)\n",
    "    content = page.read()\n",
    "    html = content.decode('utf-8')\n",
    "    \n",
    "    # create beautiful parser\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # extract paragraphs onli\n",
    "    texts = [x.text for x in soup.find_all('p')]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a686cc6-07e4-4a4e-a299-efe36b13f440",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37451ff0-c74f-428f-ad28-44ea98fb3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sanskrit(text, pattern=None):\n",
    "    # Define the Unicode range for Sanskrit characters\n",
    "    sanskrit_range = re.compile(\"[\\u0900-\\u097F]+\", re.UNICODE)\n",
    "    \n",
    "    # Check if the text contains Sanskrit characters\n",
    "    return bool(sanskrit_range.search(text))\n",
    "\n",
    "def remove_sanskrit_elements(input_list):\n",
    "    # Use list comprehension to filter out Sanskrit elements\n",
    "    filtered_list = [element for element in input_list if not is_sanskrit(element)]\n",
    "\n",
    "    return filtered_list\n",
    "\n",
    "def has_pattern(text, pattern):\n",
    "    # Use re.search to check if the pattern is present in the text\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "def remove_strings_with_pattern(input_list, pattern):\n",
    "    # Use list comprehension to filter out strings with the specified pattern\n",
    "    filtered_list = [element for element in input_list if not has_pattern(element, pattern)]\n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c6054e5-96e7-4660-af3e-eb799223081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted(text):\n",
    "    filtered = remove_sanskrit_elements(text)\n",
    "    pattern = r\"\\|\"\n",
    "    filtered = remove_strings_with_pattern(filtered, pattern)\n",
    "    return filtered    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5a88b06-4f8b-4de5-b13a-4db7976e8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "def clean_sentence(sentence, stopwords=False):\n",
    "    \"\"\"Cleans the sentences by removing stopwords and other\n",
    "    signs and symbols. Returns the formatted list of strings.\n",
    "    \"\"\"\n",
    "    formatted = sentence.lower().strip()\n",
    "    formatted = re.sub(r'[^a-z]', ' ', formatted)\n",
    "    if stopwords:\n",
    "        formatted = remove_stopwords(formatted)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48a938c-cd1c-4076-9d47-b58106e6bc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "  \"\"\"Make all necessary preprocessing of text: cleaning text and tokenizing it\n",
    "  Useful for queries, not for dataset.\n",
    "  \"\"\"\n",
    "  cleaned = clean_sentence(text, True)\n",
    "  return [word for word in cleaned.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e7f3a-7fc8-488e-8d33-dcb302d87e31",
   "metadata": {},
   "source": [
    "### main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf08b134-b0f0-403f-b9ff-69324d60d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.carakasamhitaonline.com/index.php?title=Deerghanjiviteeya_Adhyaya'\n",
    "texts = load_text_from_url(url)\n",
    "filtered = remove_unwanted(texts)\n",
    "formatted = [clean_sentence(sentence, True) for sentence in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0738e-89d6-4e96-9ad1-3e58d4c8378a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dca52ec8-7675-4639-9f06-3dbfb3fd01c4",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "831cff38-bf0c-428d-b20a-017209b75484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1a19b8-990a-4d95-aff0-14fdd752154b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████████████████| 1.18k/1.18k [00:00<00:00, 1.89MB/s]\n",
      "1_Pooling/config.json: 100%|████████████████████| 190/190 [00:00<00:00, 339kB/s]\n",
      "README.md: 100%|███████████████████████████| 10.6k/10.6k [00:00<00:00, 5.78MB/s]\n",
      "config.json: 100%|██████████████████████████████| 573/573 [00:00<00:00, 986kB/s]\n",
      "config_sentence_transformers.json: 100%|████████| 116/116 [00:00<00:00, 211kB/s]\n",
      "data_config.json: 100%|█████████████████████| 39.3k/39.3k [00:00<00:00, 193kB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████| 134M/134M [02:21<00:00, 943kB/s]\n",
      "sentence_bert_config.json: 100%|█████████████| 53.0/53.0 [00:00<00:00, 94.2kB/s]\n",
      "special_tokens_map.json: 100%|██████████████████| 112/112 [00:00<00:00, 212kB/s]\n",
      "tokenizer.json: 100%|█████████████████████████| 466k/466k [00:00<00:00, 678kB/s]\n",
      "tokenizer_config.json: 100%|████████████████████| 352/352 [00:00<00:00, 736kB/s]\n",
      "train_script.py: 100%|█████████████████████| 13.2k/13.2k [00:00<00:00, 13.7MB/s]\n",
      "vocab.txt: 100%|██████████████████████████████| 232k/232k [00:00<00:00, 532kB/s]\n",
      "modules.json: 100%|█████████████████████████████| 349/349 [00:00<00:00, 600kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aed922-6340-40f6-a2da-5ddc1076b29b",
   "metadata": {},
   "source": [
    "Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605dd457-355b-49b7-95e0-b0b2191e959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a866306a-dba6-45f8-9528-12b773aa005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array([])\n",
    "for para in formatted:\n",
    "    encoding = model.encode(para)\n",
    "    embeddings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b51b8937-1af9-451c-b15c-34adf40c1c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89743ab4-5ded-431c-b7cd-9eea4707a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings[0].shape[0])\n",
    "index.add(np.array(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1ffcf-0aa9-4822-9cb5-ce2f43b0166d",
   "metadata": {},
   "source": [
    "Query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d794dc1-0630-4e48-82f9-8f61876bb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how to treat worms\"\n",
    "# query = clean_sentence(query, True)\n",
    "query_encoding = np.array([model.encode(query)])\n",
    "D, I = index.search(query_encoding, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d745c-46c6-4754-a301-27b9a793179e",
   "metadata": {},
   "source": [
    "Most Similar Paragraph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7f01ff4b-d67f-49f4-bf58-786906db8498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The urine of cow is slightly sweet, alleviates discordance of dosha. It cures worms, skin diseases (kushtha) and relieves itching. Its proper intake cures disorders of abdomen. [101]\\n'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar = [filtered[i] for i in I[0]]\n",
    "most_similar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824775c-86a7-44eb-b248-0b18bf47e83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887724c9-99b7-400f-b524-f3a1b3380b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
